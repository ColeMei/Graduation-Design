{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "61b67bb5",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import re\n",
    "import os\n",
    "import regex as re"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "574b7fe6",
   "metadata": {},
   "source": [
    "## 1. Extract the review data from csv and save it as txt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "29a4e4a7",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define the file paths to read from\n",
    "file_paths = ['../data/北京apm.csv', '../data/王府中環.csv', '../data/王府井百货.csv', '../data/东方新天地.csv']\n",
    "\n",
    "# Loop over each file, extract the data from the 'review' column and save it to a text file\n",
    "for i, path in enumerate(file_paths):\n",
    "    # Read the CSV file\n",
    "    df = pd.read_csv(path, index_col=0)  # Set the index_col to 0 to use the first column as the index\n",
    "    # Define the path for the output text file\n",
    "    txt_path = f'../data/review/reviews_{i+1}.txt'\n",
    "    # Write the review data to the output text file\n",
    "    with open(txt_path, 'w') as f:\n",
    "        for j, review in enumerate(df['review']):\n",
    "            # Clean up the text data by removing special characters\n",
    "            review = re.sub('[\\n\\r\\t ]+', '', review)\n",
    "            # Write the review data to the output text file\n",
    "            f.write(str(review) + '\\n')\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9bda8013",
   "metadata": {},
   "source": [
    "### Merge into a new txt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "4ee4815f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define the file paths to read from\n",
    "txt_paths = ['../data/review/reviews_1.txt', '../data/review/reviews_2.txt', '../data/review/reviews_3.txt', '../data/review/reviews_4.txt']\n",
    "\n",
    "# Define the path for the output merged text file\n",
    "merged_txt_path = '../data/review/review_merged.txt'\n",
    "\n",
    "# Open the output file for writing\n",
    "with open(merged_txt_path, 'w') as merged_file:\n",
    "    # Loop over each input file\n",
    "    for txt_path in txt_paths:\n",
    "        # Open the input file for reading\n",
    "        with open(txt_path, 'r') as input_file:\n",
    "            # Loop over each line in the input file\n",
    "            for line in input_file:\n",
    "                # Write the line to the output file\n",
    "                merged_file.write(line)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "19bb27d7",
   "metadata": {},
   "source": [
    "## 2. Remove punctuation and emoji"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "d4da7078",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define the file paths to read from and write to\n",
    "input_file_paths = ['../data/review/reviews_1.txt', '../data/review/reviews_2.txt', '../data/review/reviews_3.txt', '../data/review/reviews_4.txt']\n",
    "output_file_paths = ['../data/review/processed/processed_1.txt', '../data/review/processed/processed_2.txt', '../data/review/processed/processed_3.txt', '../data/review/processed/processed_4.txt']\n",
    "\n",
    "# Define a function to process each review text\n",
    "def process_text(text):\n",
    "    # Remove all emoji\n",
    "    text = re.sub(r'\\p{Emoji}', '', text)\n",
    "    # Remove all punctuation\n",
    "    text = re.sub(r'[^\\w\\s]+', '', text)\n",
    "    # Return the processed text as a string\n",
    "    return text.strip()\n",
    "\n",
    "# Loop over each file, process the review text and save it to a new text file\n",
    "for i, input_file_path in enumerate(input_file_paths):\n",
    "    with open(input_file_path, 'r', encoding='utf-8') as input_file, open(output_file_paths[i], 'w', encoding='utf-8') as output_file:\n",
    "        for line in input_file:\n",
    "            # Process the review text\n",
    "            processed_text = process_text(line.strip())\n",
    "            # Write the processed text to the output file\n",
    "            output_file.write(processed_text + '\\n')\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "866bbc85",
   "metadata": {},
   "source": [
    "## 3. Remove stopwords"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "070f73dc",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define the file paths to read from and write to\n",
    "input_file_paths = ['../data/review/reviews_1.txt', '../data/review/reviews_2.txt', '../data/review/reviews_3.txt', '../data/review/reviews_4.txt']\n",
    "output_file_paths = ['../data/review/processed/processed_sw_1.txt', '../data/review/processed/processed_sw_2.txt', '../data/review/processed/processed_sw_3.txt', '../data/review/processed/processed_sw_4.txt']\n",
    "\n",
    "# Define the paths to your custom stop word dictionaries\n",
    "stopword_paths = ['stopwords/hit_stopwords.txt', 'stopwords/scu_stopwords.txt', 'stopwords/baidu_stopwords.txt', 'stopwords/cn_stopwords.txt']\n",
    "\n",
    "# Combine all stop word dictionaries into one set\n",
    "stopwords = set([word.strip() for path in stopword_paths for word in open(path, 'r', encoding='utf-8')])\n",
    "\n",
    "# Define a function to process each review text\n",
    "def process_text(text):\n",
    "    # Remove all emoji\n",
    "    text = re.sub(r'\\p{Emoji}', '', text)\n",
    "    # Remove all punctuation\n",
    "    text = re.sub(r'[^\\w\\s]+', '', text)\n",
    "    # Remove stop words\n",
    "    for word in stopwords:\n",
    "        text = text.replace(word, '')\n",
    "    # Return the processed text as a string\n",
    "    return text.strip()\n",
    "\n",
    "# Loop over each file, process the review text and save it to a new text file\n",
    "for i, input_file_path in enumerate(input_file_paths):\n",
    "    with open(input_file_path, 'r', encoding='utf-8') as input_file, open(output_file_paths[i], 'w', encoding='utf-8') as output_file:\n",
    "        for line in input_file:\n",
    "            # Process the review text\n",
    "            processed_text = process_text(line.strip())\n",
    "            # Write the processed text to the output file\n",
    "            output_file.write(processed_text + '\\n')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6c12b1dd",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Datascience",
   "language": "python",
   "name": "datascience"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
