{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "192f0f08",
   "metadata": {},
   "source": [
    "## 文本处理"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "43975152",
   "metadata": {},
   "outputs": [],
   "source": [
    "with open('sentiment_dic/nagtive_dic_2.txt', 'r') as f:  # 替换成实际的文件名\n",
    "    content = f.read().strip()  # 读取文件内容并去掉首尾空格\n",
    "words = content.split('、')  # 将内容按顿号分割成单独的单词，存入列表中\n",
    "\n",
    "with open('sentiment_dic/nagtive_dic_2.txt', 'w') as f:  # 替换成实际的文件名\n",
    "    for word in words:\n",
    "        f.write(word + '\\n')  # 将每个单词写入文件，并换行"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "46e0e72d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 读取第一个txt文件\n",
    "with open('sentiment_dic/nagtive_dic_1.txt', 'r') as f1:\n",
    "    content1 = f1.read().strip()  # 读取文件内容并去掉首尾空格\n",
    "words1 = content1.split('\\n')  # 将内容按换行符分割成单独的单词，存入列表中\n",
    "\n",
    "# 读取第二个txt文件\n",
    "with open('sentiment_dic/nagtive_dic_2.txt', 'r') as f2:\n",
    "    content2 = f2.read().strip()  # 读取文件内容并去掉首尾空格\n",
    "words2 = content2.split('\\n')  # 将内容按换行符分割成单独的单词，存入列表中\n",
    "\n",
    "# 合并两个列表并去除重复的内容\n",
    "words = list(set(words1 + words2))\n",
    "\n",
    "# 将内容写入新的txt文件\n",
    "with open('negative_dic_combined.txt', 'w') as f:\n",
    "    for word in words:\n",
    "        f.write(word + '\\n')  # 将每个单词写入文件，并换行"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8efbba7d",
   "metadata": {},
   "source": [
    "## 情感值计算demo"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 111,
   "id": "4c656b94",
   "metadata": {},
   "outputs": [],
   "source": [
    "import jieba\n",
    "\n",
    "# 加载情感词典\n",
    "with open('sentiment_dic/senti_dic_pro.txt', 'r', encoding='utf-8') as f:\n",
    "    sentiment_dict = json.load(f)\n",
    "\n",
    "# 加载程度副词词典\n",
    "with open('sentiment_dic/adv_dic.txt', 'r', encoding='utf-8') as f:\n",
    "    degree_dict = json.load(f)\n",
    "\n",
    "# 加载否定词词典\n",
    "with open('sentiment_dic/neg_dic.txt', 'r', encoding='utf-8') as f:\n",
    "    negation_dict = json.load(f)\n",
    "    \n",
    "# 计算单个句子的情感分数\n",
    "def sentiment_score(sen):\n",
    "    seg_list = jieba.cut(sen)  # 分词\n",
    "    seg_list = list(seg_list)\n",
    "    print(seg_list)\n",
    "    emotion_score = 0  # 情感分数\n",
    "    neg_count = 0  # 否定词数量\n",
    "    for i in range(len(seg_list)):\n",
    "        # 检查情感词\n",
    "        if seg_list[i] in sentiment_dict:\n",
    "            score = sentiment_dict[seg_list[i]]\n",
    "            degree_score = 1  # 默认程度系数为1\n",
    "            negation_score = 1  # 默认否定系数为1\n",
    "            # 在有效距离内寻找程度副词和否定词\n",
    "            for j in range(max(0, i-3), i):\n",
    "                if seg_list[j] in degree_dict:\n",
    "                    degree_score *= degree_dict[seg_list[j]]\n",
    "                elif seg_list[j] in negation_dict:\n",
    "                    neg_count += 1\n",
    "            # 根据否定词数量判断情感分数是否反转\n",
    "            if neg_count % 2 == 0:\n",
    "                emotion_score += score * degree_score\n",
    "            else:\n",
    "                emotion_score -= score * degree_score\n",
    "            neg_count = 0  # 重置否定词数量\n",
    "    return emotion_score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 112,
   "id": "a357752d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['我', '非常', '开心', '，', '甚至', '极其', '开心']\n",
      "8\n"
     ]
    }
   ],
   "source": [
    "# 测试代码\n",
    "sen = '我非常开心，甚至极其开心'\n",
    "score = sentiment_score(sen)\n",
    "print(score)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 113,
   "id": "71d3993e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['很', '极其', '难过']\n",
      "-6.0\n"
     ]
    }
   ],
   "source": [
    "# 测试代码\n",
    "sen = '很极其难过'\n",
    "score = sentiment_score(sen)\n",
    "print(score)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 114,
   "id": "4daace1f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['绝对', '很', '好']\n",
      "6.0\n"
     ]
    }
   ],
   "source": [
    "# 测试代码\n",
    "sen = '绝对很好'\n",
    "score = sentiment_score(sen)\n",
    "print(score)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 115,
   "id": "fca489b6",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['我', '好开心']\n",
      "0\n"
     ]
    }
   ],
   "source": [
    "# 测试代码\n",
    "sen = '我好开心'\n",
    "score = sentiment_score(sen)\n",
    "print(score)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 116,
   "id": "766bff0e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['我', '挺', '好', '的']\n",
      "1.6\n"
     ]
    }
   ],
   "source": [
    "# 测试代码\n",
    "sen = '我挺好的'\n",
    "score = sentiment_score(sen)\n",
    "print(score)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Datascience",
   "language": "python",
   "name": "datascience"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
