{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "192f0f08",
   "metadata": {},
   "source": [
    "## 文本处理"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "43975152",
   "metadata": {},
   "outputs": [],
   "source": [
    "with open('sentiment_dic/nagtive_dic_2.txt', 'r') as f:  # 替换成实际的文件名\n",
    "    content = f.read().strip()  # 读取文件内容并去掉首尾空格\n",
    "words = content.split('、')  # 将内容按顿号分割成单独的单词，存入列表中\n",
    "\n",
    "with open('sentiment_dic/nagtive_dic_2.txt', 'w') as f:  # 替换成实际的文件名\n",
    "    for word in words:\n",
    "        f.write(word + '\\n')  # 将每个单词写入文件，并换行"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "46e0e72d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 读取第一个txt文件\n",
    "with open('sentiment_dic/nagtive_dic_1.txt', 'r') as f1:\n",
    "    content1 = f1.read().strip()  # 读取文件内容并去掉首尾空格\n",
    "words1 = content1.split('\\n')  # 将内容按换行符分割成单独的单词，存入列表中\n",
    "\n",
    "# 读取第二个txt文件\n",
    "with open('sentiment_dic/nagtive_dic_2.txt', 'r') as f2:\n",
    "    content2 = f2.read().strip()  # 读取文件内容并去掉首尾空格\n",
    "words2 = content2.split('\\n')  # 将内容按换行符分割成单独的单词，存入列表中\n",
    "\n",
    "# 合并两个列表并去除重复的内容\n",
    "words = list(set(words1 + words2))\n",
    "\n",
    "# 将内容写入新的txt文件\n",
    "with open('negative_dic_combined.txt', 'w') as f:\n",
    "    for word in words:\n",
    "        f.write(word + '\\n')  # 将每个单词写入文件，并换行"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8efbba7d",
   "metadata": {},
   "source": [
    "## 情感值计算demo"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 111,
   "id": "4c656b94",
   "metadata": {},
   "outputs": [],
   "source": [
    "import jieba\n",
    "\n",
    "# 加载情感词典\n",
    "with open('sentiment_dic/senti_dic_pro.txt', 'r', encoding='utf-8') as f:\n",
    "    sentiment_dict = json.load(f)\n",
    "\n",
    "# 加载程度副词词典\n",
    "with open('sentiment_dic/adv_dic.txt', 'r', encoding='utf-8') as f:\n",
    "    degree_dict = json.load(f)\n",
    "\n",
    "# 加载否定词词典\n",
    "with open('sentiment_dic/neg_dic.txt', 'r', encoding='utf-8') as f:\n",
    "    negation_dict = json.load(f)\n",
    "    \n",
    "# 计算单个句子的情感分数\n",
    "def sentiment_score(sen):\n",
    "    seg_list = jieba.cut(sen)  # 分词\n",
    "    seg_list = list(seg_list)\n",
    "    print(seg_list)\n",
    "    emotion_score = 0  # 情感分数\n",
    "    neg_count = 0  # 否定词数量\n",
    "    for i in range(len(seg_list)):\n",
    "        # 检查情感词\n",
    "        if seg_list[i] in sentiment_dict:\n",
    "            score = sentiment_dict[seg_list[i]]\n",
    "            degree_score = 1  # 默认程度系数为1\n",
    "            negation_score = 1  # 默认否定系数为1\n",
    "            # 在有效距离内寻找程度副词和否定词\n",
    "            for j in range(max(0, i-3), i):\n",
    "                if seg_list[j] in degree_dict:\n",
    "                    degree_score *= degree_dict[seg_list[j]]\n",
    "                elif seg_list[j] in negation_dict:\n",
    "                    neg_count += 1\n",
    "            # 根据否定词数量判断情感分数是否反转\n",
    "            if neg_count % 2 == 0:\n",
    "                emotion_score += score * degree_score\n",
    "            else:\n",
    "                emotion_score -= score * degree_score\n",
    "            neg_count = 0  # 重置否定词数量\n",
    "    return emotion_score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 112,
   "id": "a357752d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['我', '非常', '开心', '，', '甚至', '极其', '开心']\n",
      "8\n"
     ]
    }
   ],
   "source": [
    "# 测试代码\n",
    "sen = '我非常开心，甚至极其开心'\n",
    "score = sentiment_score(sen)\n",
    "print(score)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 113,
   "id": "71d3993e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['很', '极其', '难过']\n",
      "-6.0\n"
     ]
    }
   ],
   "source": [
    "# 测试代码\n",
    "sen = '很极其难过'\n",
    "score = sentiment_score(sen)\n",
    "print(score)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 114,
   "id": "4daace1f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['绝对', '很', '好']\n",
      "6.0\n"
     ]
    }
   ],
   "source": [
    "# 测试代码\n",
    "sen = '绝对很好'\n",
    "score = sentiment_score(sen)\n",
    "print(score)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 115,
   "id": "fca489b6",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['我', '好开心']\n",
      "0\n"
     ]
    }
   ],
   "source": [
    "# 测试代码\n",
    "sen = '我好开心'\n",
    "score = sentiment_score(sen)\n",
    "print(score)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 116,
   "id": "766bff0e",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['我', '挺', '好', '的']\n",
      "1.6\n"
     ]
    }
   ],
   "source": [
    "# 测试代码\n",
    "sen = '我挺好的'\n",
    "score = sentiment_score(sen)\n",
    "print(score)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5241f789",
   "metadata": {},
   "source": [
    "## 代码行数统计"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "f2154140",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/Users/colemei/Desktop/Graduation Design/source/Data-Analysis-02.ipynb: Code lines: 974, Comment lines: 83\n",
      "/Users/colemei/Desktop/Graduation Design/source/Data-PreProcessing-01.ipynb: Code lines: 734, Comment lines: 94\n",
      "/Users/colemei/Desktop/Graduation Design/source/Data-Analysis-01.ipynb: Code lines: 1134, Comment lines: 151\n",
      "/Users/colemei/Desktop/Graduation Design/source/Data-Analysis-03.ipynb: Code lines: 448, Comment lines: 40\n",
      "/Users/colemei/Desktop/Graduation Design/source/Content-Mining-01.ipynb: Code lines: 1468, Comment lines: 92\n",
      "/Users/colemei/Desktop/Graduation Design/source/Data-Cleaning-02.ipynb: Code lines: 1421, Comment lines: 62\n",
      "/Users/colemei/Desktop/Graduation Design/source/Others.ipynb: Code lines: 426, Comment lines: 40\n",
      "/Users/colemei/Desktop/Graduation Design/source/Data-Storage-01.ipynb: Code lines: 163, Comment lines: 20\n",
      "/Users/colemei/Desktop/Graduation Design/source/Data-Cleaning-01.ipynb: Code lines: 501, Comment lines: 5\n",
      "Total Code lines: 7269\n",
      "Total Comment lines: 587\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import re\n",
    "\n",
    "def count_code_lines(file_path):\n",
    "    code_count = 0\n",
    "    comment_count = 0\n",
    "    with open(file_path, 'r', encoding='utf-8') as file:\n",
    "        lines = file.readlines()\n",
    "        is_in_comment = False\n",
    "        for line in lines:\n",
    "            stripped_line = line.strip()\n",
    "            if stripped_line:\n",
    "                if stripped_line.startswith('#'):\n",
    "                    comment_count += 1\n",
    "                else:\n",
    "                    if re.search(r'#', stripped_line):\n",
    "                        comment_count += 1\n",
    "                    code_count += 1\n",
    "    return code_count, comment_count\n",
    "\n",
    "def count_total_lines(folder_path):\n",
    "    total_code_count = 0\n",
    "    total_comment_count = 0\n",
    "    for file in os.listdir(folder_path):\n",
    "        file_path = os.path.join(folder_path, file)\n",
    "        if file.endswith('.ipynb') and os.path.isfile(file_path):\n",
    "            code_count, comment_count = count_code_lines(file_path)\n",
    "            total_code_count += code_count\n",
    "            total_comment_count += comment_count\n",
    "            print(f\"{file_path}: Code lines: {code_count}, Comment lines: {comment_count}\")\n",
    "    print(f\"Total Code lines: {total_code_count}\")\n",
    "    print(f\"Total Comment lines: {total_comment_count}\")\n",
    "\n",
    "current_directory = os.getcwd()\n",
    "count_total_lines(current_directory)\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Datascience",
   "language": "python",
   "name": "datascience"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
