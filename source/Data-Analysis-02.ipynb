{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "1fc9c849",
   "metadata": {},
   "source": [
    "# Part 2. Topic analysis of positive and negative comments using LDA models"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "id": "7cc87f80",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import csv\n",
    "import gensim\n",
    "from gensim.corpora import Dictionary\n",
    "from gensim.models import LdaModel\n",
    "from gensim.models import CoherenceModel\n",
    "import pyLDAvis.gensim\n",
    "import numpy as np\n",
    "from sklearn.metrics.pairwise import cosine_similarity\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "191f4f6b",
   "metadata": {},
   "source": [
    "## 1. Calculation of the optimal number of topics"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "21860fc4",
   "metadata": {},
   "source": [
    "### Function Design : Use Perplexity and Coherence "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "46643d58",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_optimal_topic_num_by_perplexity(file_path, num_topics_range):\n",
    "    '''\n",
    "    Compute the optimal number of topics.\n",
    "\n",
    "    Parameters:\n",
    "    file_path: str, the file path of the preprocessed text file.\n",
    "    num_topics_range: list, the range of topic numbers to try.\n",
    "\n",
    "    Returns:\n",
    "    best_num_topics: int, the optimal number of topics.\n",
    "    '''\n",
    "\n",
    "    # Read the file and create the corpus.\n",
    "    with open(file_path, 'r', encoding='utf-8') as f:\n",
    "        corpus = [line.strip().split() for line in f]\n",
    "\n",
    "    # Create the dictionary.\n",
    "    dictionary = Dictionary(corpus)\n",
    "\n",
    "    # Train the LDA models with different topic numbers, and calculate the perplexity values.\n",
    "    perplexity_values = []\n",
    "    lda_models = []\n",
    "    for num_topics in num_topics_range:\n",
    "        lda_model = LdaModel(corpus=[dictionary.doc2bow(text) for text in corpus], id2word=dictionary, num_topics=num_topics)\n",
    "        lda_models.append(lda_model)\n",
    "        perplexity_values.append(lda_model.log_perplexity([dictionary.doc2bow(text) for text in corpus]))\n",
    "\n",
    "    # Calculate the coherence scores using the perplexity values.\n",
    "    coherence_scores = [CoherenceModel(model=lda_model, texts=corpus, dictionary=dictionary, coherence='c_v').get_coherence() for lda_model in lda_models]\n",
    "\n",
    "    # Find the optimal number of topics based on the coherence scores.\n",
    "    best_num_topics_index = coherence_scores.index(max(coherence_scores))\n",
    "    best_num_topics = num_topics_range[best_num_topics_index]\n",
    "    \n",
    "    print(\"Optimal number of topics (using perplexity method):\", best_num_topics)\n",
    "\n",
    "    return best_num_topics\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8b2fc02e",
   "metadata": {},
   "source": [
    "### Function Design : Use Cosine_Similarity"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "1520aa3c",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_optimal_topic_num_by_similarity(file_path, num_topics_range):\n",
    "    '''\n",
    "    Compute the optimal number of topics.\n",
    "\n",
    "    Parameters:\n",
    "    file_path: str, the file path of the preprocessed text file.\n",
    "    num_topics_range: list, the range of topic numbers to try.\n",
    "\n",
    "    Returns:\n",
    "    best_num_topics: int, the optimal number of topics.\n",
    "    '''\n",
    "    # Read file and create corpus\n",
    "    with open(file_path, 'r', encoding='utf-8') as f:\n",
    "        corpus = [line.strip().split() for line in f]\n",
    "\n",
    "    # Create dictionary\n",
    "    dictionary = gensim.corpora.Dictionary(corpus)\n",
    "\n",
    "    # Train LDA model and compute cosine similarity between topics for different number of topics\n",
    "    similarity_values = []\n",
    "    for num_topics in num_topics_range:\n",
    "        lda_model = gensim.models.ldamodel.LdaModel(corpus=[dictionary.doc2bow(text) for text in corpus], id2word=dictionary, num_topics=num_topics)\n",
    "        topics_matrix = lda_model.get_topics()\n",
    "        cosine_similarities = cosine_similarity(topics_matrix)\n",
    "        similarity_values.append(np.min(cosine_similarities[np.triu_indices(num_topics, k=1)]))\n",
    "\n",
    "    # Find the optimal number of topics\n",
    "    best_num_topics_index = similarity_values.index(max(similarity_values))\n",
    "    best_num_topics = num_topics_range[best_num_topics_index]\n",
    "    \n",
    "    print(\"Optimal number of topics (using cosine similarity method):\", best_num_topics)\n",
    "    \n",
    "    return best_num_topics\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "974cc298",
   "metadata": {},
   "source": [
    "### Call the function to output the respective optimal number of topics"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "a284f4f7",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create a list of integers for the range of number of topics.\n",
    "num_topics_range = list(range(3, 10))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3d8f9dcc",
   "metadata": {},
   "source": [
    "#### For stores 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "d5bb3037",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Optimal number of topics (using perplexity method): 8\n",
      "Optimal number of topics (using cosine similarity method): 3\n",
      "Ultimate optimal number of topics : 5\n"
     ]
    }
   ],
   "source": [
    "# Set the file path for a text file.\n",
    "file_path = \"../data/review/analysis/polarity/reviews_1_polarity_P.txt\"\n",
    "\n",
    "# Get the optimal number of topics based on perplexity and cosine similarity.\n",
    "best_num_topics_perplexity = get_optimal_topic_num_by_perplexity(file_path, num_topics_range)\n",
    "best_num_topics_similarity = get_optimal_topic_num_by_similarity(file_path, num_topics_range)\n",
    "\n",
    "# Print the ultimate optimal number of topics.\n",
    "P1_best_num_topics = int((best_num_topics_perplexity + best_num_topics_similarity)/2)\n",
    "print(\"Ultimate optimal number of topics :\", P1_best_num_topics)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "b8a73cef",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Optimal number of topics (using perplexity method): 4\n",
      "Optimal number of topics (using cosine similarity method): 3\n",
      "Ultimate optimal number of topics : 3\n"
     ]
    }
   ],
   "source": [
    "# Set the file path for a text file.\n",
    "file_path = \"../data/review/analysis/polarity/reviews_1_polarity_N.txt\"\n",
    "\n",
    "# Get the optimal number of topics based on perplexity and cosine similarity.\n",
    "best_num_topics_perplexity = get_optimal_topic_num_by_perplexity(file_path, num_topics_range)\n",
    "best_num_topics_similarity = get_optimal_topic_num_by_similarity(file_path, num_topics_range)\n",
    "\n",
    "# Print the ultimate optimal number of topics.\n",
    "N1_best_num_topics = int((best_num_topics_perplexity + best_num_topics_similarity)/2)\n",
    "print(\"Ultimate optimal number of topics :\", N1_best_num_topics)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "16a2cbc5",
   "metadata": {},
   "source": [
    "#### For stores 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "2e02acd6",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Optimal number of topics (using perplexity method): 8\n",
      "Optimal number of topics (using cosine similarity method): 3\n",
      "Ultimate optimal number of topics : 5\n"
     ]
    }
   ],
   "source": [
    "# Set the file path for a text file.\n",
    "file_path = \"../data/review/analysis/polarity/reviews_2_polarity_P.txt\"\n",
    "\n",
    "# Get the optimal number of topics based on perplexity and cosine similarity.\n",
    "best_num_topics_perplexity = get_optimal_topic_num_by_perplexity(file_path, num_topics_range)\n",
    "best_num_topics_similarity = get_optimal_topic_num_by_similarity(file_path, num_topics_range)\n",
    "\n",
    "# Print the ultimate optimal number of topics.\n",
    "P2_best_num_topics = int((best_num_topics_perplexity + best_num_topics_similarity)/2)\n",
    "print(\"Ultimate optimal number of topics :\", P2_best_num_topics)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "74457bc5",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Optimal number of topics (using perplexity method): 6\n",
      "Optimal number of topics (using cosine similarity method): 3\n",
      "Ultimate optimal number of topics : 4\n"
     ]
    }
   ],
   "source": [
    "# Set the file path for a text file.\n",
    "file_path = \"../data/review/analysis/polarity/reviews_2_polarity_N.txt\"\n",
    "\n",
    "# Get the optimal number of topics based on perplexity and cosine similarity.\n",
    "best_num_topics_perplexity = get_optimal_topic_num_by_perplexity(file_path, num_topics_range)\n",
    "best_num_topics_similarity = get_optimal_topic_num_by_similarity(file_path, num_topics_range)\n",
    "\n",
    "# Print the ultimate optimal number of topics.\n",
    "N2_best_num_topics = int((best_num_topics_perplexity + best_num_topics_similarity)/2)\n",
    "print(\"Ultimate optimal number of topics :\", N2_best_num_topics)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2609e10c",
   "metadata": {},
   "source": [
    "#### For stores 3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "fa66810a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Optimal number of topics (using perplexity method): 3\n",
      "Optimal number of topics (using cosine similarity method): 3\n",
      "Ultimate optimal number of topics : 3\n"
     ]
    }
   ],
   "source": [
    "# Set the file path for a text file.\n",
    "file_path = \"../data/review/analysis/polarity/reviews_3_polarity_P.txt\"\n",
    "\n",
    "# Get the optimal number of topics based on perplexity and cosine similarity.\n",
    "best_num_topics_perplexity = get_optimal_topic_num_by_perplexity(file_path, num_topics_range)\n",
    "best_num_topics_similarity = get_optimal_topic_num_by_similarity(file_path, num_topics_range)\n",
    "\n",
    "# Print the ultimate optimal number of topics.\n",
    "P3_best_num_topics = int((best_num_topics_perplexity + best_num_topics_similarity)/2)\n",
    "print(\"Ultimate optimal number of topics :\", P3_best_num_topics)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "c24bc816",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Optimal number of topics (using perplexity method): 9\n",
      "Optimal number of topics (using cosine similarity method): 3\n",
      "Ultimate optimal number of topics : 6\n"
     ]
    }
   ],
   "source": [
    "# Set the file path for a text file.\n",
    "file_path = \"../data/review/analysis/polarity/reviews_3_polarity_N.txt\"\n",
    "\n",
    "# Get the optimal number of topics based on perplexity and cosine similarity.\n",
    "best_num_topics_perplexity = get_optimal_topic_num_by_perplexity(file_path, num_topics_range)\n",
    "best_num_topics_similarity = get_optimal_topic_num_by_similarity(file_path, num_topics_range)\n",
    "\n",
    "# Print the ultimate optimal number of topics.\n",
    "N3_best_num_topics = int((best_num_topics_perplexity + best_num_topics_similarity)/2)\n",
    "print(\"Ultimate optimal number of topics :\", N3_best_num_topics)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5259fed7",
   "metadata": {},
   "source": [
    "#### For stores 4"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "656236ab",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Optimal number of topics (using perplexity method): 8\n",
      "Optimal number of topics (using cosine similarity method): 3\n",
      "Ultimate optimal number of topics : 5\n"
     ]
    }
   ],
   "source": [
    "# Set the file path for a text file.\n",
    "file_path = \"../data/review/analysis/polarity/reviews_4_polarity_P.txt\"\n",
    "\n",
    "# Get the optimal number of topics based on perplexity and cosine similarity.\n",
    "best_num_topics_perplexity = get_optimal_topic_num_by_perplexity(file_path, num_topics_range)\n",
    "best_num_topics_similarity = get_optimal_topic_num_by_similarity(file_path, num_topics_range)\n",
    "\n",
    "# Print the ultimate optimal number of topics.\n",
    "P4_best_num_topics = int((best_num_topics_perplexity + best_num_topics_similarity)/2)\n",
    "print(\"Ultimate optimal number of topics :\", P4_best_num_topics)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "e411afc9",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Optimal number of topics (using perplexity method): 6\n",
      "Optimal number of topics (using cosine similarity method): 3\n",
      "Ultimate optimal number of topics : 4\n"
     ]
    }
   ],
   "source": [
    "# Set the file path for a text file.\n",
    "file_path = \"../data/review/analysis/polarity/reviews_4_polarity_N.txt\"\n",
    "\n",
    "# Get the optimal number of topics based on perplexity and cosine similarity.\n",
    "best_num_topics_perplexity = get_optimal_topic_num_by_perplexity(file_path, num_topics_range)\n",
    "best_num_topics_similarity = get_optimal_topic_num_by_similarity(file_path, num_topics_range)\n",
    "\n",
    "# Print the ultimate optimal number of topics.\n",
    "N4_best_num_topics = int((best_num_topics_perplexity + best_num_topics_similarity)/2)\n",
    "print(\"Ultimate optimal number of topics :\", N4_best_num_topics)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d0358879",
   "metadata": {},
   "source": [
    "## 2. Get Topic-Word Distribution"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "44c6c89c",
   "metadata": {},
   "source": [
    "### Function design : LDA model training, topic-word distribution output and visualization"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "bd7c5500",
   "metadata": {},
   "outputs": [],
   "source": [
    "def lda_topic_modeling(file_path, num_topics):\n",
    "    # Read the text file\n",
    "    with open(file_path, \"r\", encoding=\"utf-8\") as f:\n",
    "        texts = [line.strip().split() for line in f]\n",
    "\n",
    "    # Build the dictionary and bag-of-words model\n",
    "    dictionary = Dictionary(texts)\n",
    "    print(dictionary)\n",
    "    \n",
    "    # Filter out extreme terms based on frequency and document proportion\n",
    "    dictionary.filter_extremes(no_below=5, no_above=0.1)\n",
    "    print(dictionary)\n",
    "    \n",
    "    # Convert texts into bag-of-words format\n",
    "    corpus = [dictionary.doc2bow(doc) for doc in texts]\n",
    "\n",
    "    # Train the LDA model\n",
    "    lda_model = LdaModel(corpus=corpus, \n",
    "                         num_topics=num_topics, \n",
    "                         id2word=dictionary, \n",
    "                         random_state=100,\n",
    "                         update_every=1,\n",
    "                         chunksize=100,\n",
    "                         passes=10,\n",
    "                         alpha='auto',\n",
    "                         per_word_topics=True)\n",
    "\n",
    "    # Print the top keywords for each topic\n",
    "    for topic_id in range(num_topics):\n",
    "        topic_words = lda_model.show_topic(topic_id, topn=20)\n",
    "        print(\"Topic {}: {}\".format(topic_id, \", \".join([word for word, prob in topic_words])))\n",
    "\n",
    "    # Compute visualization data for the LDA model\n",
    "    vis_data = pyLDAvis.gensim.prepare(lda_model, corpus, dictionary)\n",
    "\n",
    "    # Extract a portion of the file path as the filename\n",
    "    filename = os.path.splitext(os.path.basename(file_path))[0]\n",
    "    filename = \"pyLDAvis/lda_visualization_{}.html\".format(filename)\n",
    "\n",
    "    # Save the visualization as an HTML file\n",
    "    pyLDAvis.save_html(vis_data, filename)\n",
    "    print(\"Visualization saved as:\", filename)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2089a946",
   "metadata": {},
   "source": [
    "### Call the function to Complete LDA theme analysis"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0e541725",
   "metadata": {},
   "source": [
    "#### For stores 1"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "198bed41",
   "metadata": {},
   "source": [
    "#### Postive review"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "840d0e24",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Dictionary<15034 unique tokens: ['apm', '一圈', '一家', '不错', '云集']...>\n",
      "Dictionary<3103 unique tokens: ['apm', '一圈', '一家', '不错', '云集']...>\n",
      "Topic 0: 不, 没, 走, 没有, 新东安, 打折, 装修, 消费, 更, 品牌\n",
      "Topic 1: 活动, 可爱, 拍照, 展览, 小样, 游戏, 兰蔻, 领, 中心, 中庭\n",
      "Topic 2: 很, 王府井, 逛, 好, 吃, 多, 还, 喜欢, 品牌, 非常\n",
      "Topic 3: 购物, 品牌, 苹果, 北京, 时尚, 王府井大街, 步行街, 店, 美食, 餐饮\n",
      "Topic 4: apm, 北京, 做, 东安市场, 打卡, 朋友, 正好, 好看, 好去处, 超级\n",
      "Visualization saved as: pyLDAvis/lda_visualization_reviews_1_polarity_P.html\n"
     ]
    }
   ],
   "source": [
    "file_path = \"../data/review/analysis/polarity/reviews_1_polarity_P.txt\"\n",
    "lda_topic_modeling(file_path, P1_best_num_topics)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4eb41550",
   "metadata": {},
   "source": [
    "#### Negative review"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "3ab4074d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Dictionary<5557 unique tokens: ['休息', '地方', '坐下', '座位', '想']...>\n",
      "Dictionary<715 unique tokens: ['休息', '地方', '想', '没有', '顾客']...>\n",
      "Topic 0: 商场, 王府井, 品牌, 很, apm, 北京, 一些, 一层, 逛, 东安市场\n",
      "Topic 1: 活动, apm, 打卡, 拍照, ️, 北京, 展览, 月, 时间, 玩\n",
      "Topic 2: 不, 还, 没, 多, 买, 没有, 挺, 说, 逛, 疫情\n",
      "Visualization saved as: pyLDAvis/lda_visualization_reviews_1_polarity_N.html\n"
     ]
    }
   ],
   "source": [
    "file_path = \"../data/review/analysis/polarity/reviews_1_polarity_N.txt\"\n",
    "lda_topic_modeling(file_path, N1_best_num_topics)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "25f1b21f",
   "metadata": {},
   "source": [
    "#### For stores 2"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b34fd400",
   "metadata": {},
   "source": [
    "#### Postive review"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "1f6033f0",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Dictionary<13572 unique tokens: ['cafelandmark', '一共', '一块', '一杯', '万朵']...>\n",
      "Dictionary<2515 unique tokens: ['一共', '一块', '一杯', '万朵', '上班']...>\n",
      "Topic 0: 很, 好, 商场, 喜欢, 非常, 特别, 环境, 可爱, 最, 里\n",
      "Topic 1: 商场, 王府井, 品牌, 王府中环, 高端, 餐厅, 大牌, 环境, 不错, 购物\n",
      "Topic 2: 很, 还, 不, 多, 吃, 王府中环, 买, 适合, 好, 拍照\n",
      "Topic 3: 怪兽, 孩子, 带, 积分, 圣诞, 展览, 有趣, 玩, 兑换, 装饰\n",
      "Topic 4: 可可, 咖啡, ️, 互动, 制作, 文化, 活动, 一群, 举办, 创意\n",
      "Visualization saved as: pyLDAvis/lda_visualization_reviews_2_polarity_P.html\n"
     ]
    }
   ],
   "source": [
    "file_path = \"../data/review/analysis/polarity/reviews_2_polarity_P.txt\"\n",
    "lda_topic_modeling(file_path, P2_best_num_topics)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a1decf05",
   "metadata": {},
   "source": [
    "#### Negative review"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "fb0d017f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Dictionary<3895 unique tokens: ['B', 'DROPOFF', '不是', '东', '位置']...>\n",
      "Dictionary<395 unique tokens: ['B', '不是', '位置', '停车场', '免费']...>\n",
      "Topic 0: 工厂, 巧克力, 活动, 怪物, 创意, 怪兽, 圣诞节, 展览, 停车费, skp\n",
      "Topic 1: 咖啡, 冰场, 票, 喝, 场地, 青年节, 咖啡节, 现场, 户外, 咖啡店\n",
      "Topic 2: 玩, 买, 孩子, 小朋友, 说, 真的, 地方, 滑冰, 朋友, 走\n",
      "Topic 3: 商场, 不, 王府中环, 很, 没有, 王府井, 地方, 多, 还, 品牌\n",
      "Visualization saved as: pyLDAvis/lda_visualization_reviews_2_polarity_N.html\n"
     ]
    }
   ],
   "source": [
    "file_path = \"../data/review/analysis/polarity/reviews_2_polarity_N.txt\"\n",
    "lda_topic_modeling(file_path, N2_best_num_topics)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "77c9ab57",
   "metadata": {},
   "source": [
    "#### For stores 3"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b01f2f33",
   "metadata": {},
   "source": [
    "#### Postive review"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "4ae3525e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Dictionary<8982 unique tokens: ['一楼', '五花八门', '价格', '全国劳模', '北京']...>\n",
      "Dictionary<1468 unique tokens: ['一楼', '价格', '全国劳模', '北京', '品类']...>\n",
      "Topic 0: 化妆品, ️, 专柜, 买, 一层, 优惠, 推荐, 好, 羊毛, 薅\n",
      "Topic 1: 很, 王府井, 商场, 北京, 好, 还, 逛, 感觉, 不错, 不\n",
      "Topic 2: 老, 北京, 和平, 地下, 菓, 局, 回忆, 北京市, 新, 记忆\n",
      "Visualization saved as: pyLDAvis/lda_visualization_reviews_3_polarity_P.html\n"
     ]
    }
   ],
   "source": [
    "file_path = \"../data/review/analysis/polarity/reviews_3_polarity_P.txt\"\n",
    "lda_topic_modeling(file_path, P3_best_num_topics)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5498348c",
   "metadata": {},
   "source": [
    "#### Negative review"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "a7eb53c1",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Dictionary<3461 unique tokens: ['一层', '之选', '优秀', '吃', '商场']...>\n",
      "Dictionary<343 unique tokens: ['一层', '吃', '商场', '地下', '地方']...>\n",
      "Topic 0: 商场, 不, 没有, 王府井, 很, 东西, 多, 说, 不是, 真的\n",
      "Topic 1: 排队, 小样, 领, apm, 挺, 化妆品, 旋转, 木马, 玩, 雅诗兰黛\n",
      "Topic 2: 带, 很, 小时候, 孩子, 回忆, 玩, 买, 挺, 生活, 感觉\n",
      "Topic 3: 体验, 负, 可, 自行车, 仿佛, 火车, 零食, 带, 玩, 玩具\n",
      "Topic 4: 北京, 老, 地下, 王府井, 二层, 一层, 和平, 还, 没, 胡同\n",
      "Topic 5: 王府井, 儿时, 记忆, 北京, 步行街, 选择, 打卡, 地下, 北楼, 场景\n",
      "Visualization saved as: pyLDAvis/lda_visualization_reviews_3_polarity_N.html\n"
     ]
    }
   ],
   "source": [
    "file_path = \"../data/review/analysis/polarity/reviews_3_polarity_N.txt\"\n",
    "lda_topic_modeling(file_path, N3_best_num_topics)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e697600c",
   "metadata": {},
   "source": [
    "#### For stores 4"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bdca8b0f",
   "metadata": {},
   "source": [
    "#### Postive review"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "1a445f21",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Dictionary<6685 unique tokens: ['一风堂', '不错', '停车', '吃', '商场']...>\n",
      "Dictionary<996 unique tokens: ['不错', '停车', '吃', '商场', '地下']...>\n",
      "Topic 0: 疫情, 不, 没, 期间, 热闹, 里, 真的, 几个, 顾客, 喝\n",
      "Topic 1: 停车, 逛街, 免费, 周末, 小时, 积分, 价格, 会员, 活动, 溜达\n",
      "Topic 2: 王府井, 东方新天地, 购物, 东单, 北京, 长安街, 餐饮, 新天地, 高端, 交通\n",
      "Topic 3: 年, 写字楼, 可爱, 东方广场, 一家, 繁华, 楼下, 喷泉, 最, 广场\n",
      "Topic 4: 商场, 很, 好, 品牌, 东方新天地, 逛, 多, 喜欢, 王府井, 非常\n",
      "Visualization saved as: pyLDAvis/lda_visualization_reviews_4_polarity_P.html\n"
     ]
    }
   ],
   "source": [
    "file_path = \"../data/review/analysis/polarity/reviews_4_polarity_P.txt\"\n",
    "lda_topic_modeling(file_path, P4_best_num_topics)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9ac57115",
   "metadata": {},
   "source": [
    "#### Negative review"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "ed93eedf",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Dictionary<2630 unique tokens: ['一站式', '不便', '东长安街', '享受', '人流']...>\n",
      "Dictionary<202 unique tokens: ['价格', '停车', '北京', '吃喝玩乐', '白领']...>\n",
      "Topic 0: 东方新天地, 王府井, 活动, 东单, 逛, 还, 一层, 疫情, 地铁, 很\n",
      "Topic 1: 说, 不, 积分, 还, 疫情, 没, 保安, 非常, 问, 期间\n",
      "Topic 2: 地下, 多, 没有, 很, 不, 一层, 品牌, 特别, 开门, 店铺\n",
      "Topic 3: 没有, 吃, 不是, 还, 逛, 没, 第一次, 找, 很, 地方\n",
      "Visualization saved as: pyLDAvis/lda_visualization_reviews_4_polarity_N.html\n"
     ]
    }
   ],
   "source": [
    "file_path = \"../data/review/analysis/polarity/reviews_4_polarity_N.txt\"\n",
    "lda_topic_modeling(file_path, N4_best_num_topics)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b6f2c640",
   "metadata": {},
   "source": [
    "## 3. LDA thematic analysis of all review texts in the business circle"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "59f089b3",
   "metadata": {},
   "source": [
    "### Get the optimal number of topics (same as below)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "6a341fb0",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Optimal number of topics (using perplexity method): 9\n",
      "Optimal number of topics (using cosine similarity method): 3\n",
      "Ultimate optimal number of topics : 6\n"
     ]
    }
   ],
   "source": [
    "# Set the file path for a text file.\n",
    "file_path = \"../data/review/processed/reviews_merged.txt\"\n",
    "\n",
    "# Get the optimal number of topics based on perplexity and cosine similarity.\n",
    "best_num_topics_perplexity = get_optimal_topic_num_by_perplexity(file_path, num_topics_range)\n",
    "best_num_topics_similarity = get_optimal_topic_num_by_similarity(file_path, num_topics_range)\n",
    "\n",
    "# Print the ultimate optimal number of topics.\n",
    "best_num_topics = int((best_num_topics_perplexity + best_num_topics_similarity)/2)\n",
    "print(\"Ultimate optimal number of topics :\", best_num_topics)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "279f3024",
   "metadata": {},
   "source": [
    "### Improve \" lda_topic_modeling \" function, adjust parameters and add new functions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "id": "3d702076",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "def lda_topic_modeling_with_assignment(file_path, num_topics, output_file):\n",
    "    # Read the text file\n",
    "    with open(file_path, \"r\", encoding=\"utf-8\") as f:\n",
    "        comments = [line.strip() for line in f]\n",
    "\n",
    "    # Build the dictionary and bag-of-words model\n",
    "    dictionary = Dictionary([comment.split() for comment in comments])\n",
    "    print(dictionary)\n",
    "    dictionary.filter_extremes(no_below=5, no_above=0.1)\n",
    "    print(dictionary)\n",
    "    \n",
    "    # Convert comments into bag-of-words format\n",
    "    corpus = [dictionary.doc2bow(comment.split()) for comment in comments]\n",
    "\n",
    "    # Train the LDA model\n",
    "    lda_model = LdaModel(corpus=corpus, \n",
    "                         num_topics=num_topics, \n",
    "                         id2word=dictionary, \n",
    "                         random_state=100,\n",
    "                         update_every=1,\n",
    "                         chunksize=100,\n",
    "                         passes=10,\n",
    "                         alpha='auto',\n",
    "                         per_word_topics=True)\n",
    "\n",
    "    # Assign topics to comments\n",
    "    topic_assignments = []\n",
    "    for bow in corpus:\n",
    "        doc_topics = lda_model.get_document_topics(bow)\n",
    "        topic_assignments.append(max(doc_topics, key=lambda x: x[1])[0])\n",
    "\n",
    "    # Print the top keywords for each topic\n",
    "    for topic_id in range(num_topics):\n",
    "        topic_words = lda_model.show_topic(topic_id, topn=20)\n",
    "        print(\"Topic {}: {}\".format(topic_id, \", \".join([word for word, prob in topic_words])))\n",
    "\n",
    "    # Write the topic assignments to a CSV file\n",
    "    with open(output_file, \"w\", encoding=\"utf-8\", newline=\"\") as f:\n",
    "        writer = csv.writer(f)\n",
    "        writer.writerow([\"review_splitting\", \"topic\"])\n",
    "        for comment, topic in zip(comments, topic_assignments):\n",
    "            writer.writerow([comment, topic])\n",
    "    print(\"Topic assignments saved in:\", output_file)\n",
    "\n",
    "    # Compute visualization data for the LDA model\n",
    "    vis_data = pyLDAvis.gensim.prepare(lda_model, corpus, dictionary)\n",
    "\n",
    "    # Extract a portion of the file path as the filename\n",
    "    filename = os.path.splitext(os.path.basename(file_path))[0]\n",
    "    filename = \"pyLDAvis/lda_visualization_{}.html\".format(filename)\n",
    "\n",
    "    # Save the visualization as an HTML file\n",
    "    pyLDAvis.save_html(vis_data, filename)\n",
    "    print(\"Visualization saved as:\", filename)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "id": "683f3fab",
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Dictionary<30619 unique tokens: ['apm', '一圈', '一家', '不错', '云集']...>\n",
      "Dictionary<6900 unique tokens: ['一圈', '一家', '云集', '交通', '人气']...>\n",
      "Topic 0: 购物, 东单, 餐饮, 停车, 东方广场, 新天地, 位于, 积分, 停车场, 消费, 小时, 顾客, 设施, 会员, 购物中心, 休闲, 商业, 娱乐, 商业街, 区\n",
      "Topic 1: 东方新天地, 地铁, 吃饭, 店铺, 一些, 大牌, 逛街, 位置, 最, 步行街, 逛逛, 长安街, 不少, 很大, 适合, 朋友, 不过, 高端, 交通, 王府井大街\n",
      "Topic 2: 时间, 免费, 小时候, 希望, 价格, 点, 打卡, 超市, 卖, 人少, 路过, 发现, 生活, 可爱, 记忆, 展览, 展, 综合性, 主题, 区域\n",
      "Topic 3: 疫情, 说, 不是, 东西, 走, 想, 太, 过, 带, 找, 期间, 更, 少, 服务, 喷泉, 孩子, 北京市, 第一次, 有些, 晚上\n",
      "Topic 4: 拍照, ️, 繁华, 有个, 拍, 分, 快, 满满的, 回到, 美食街, 儿时, 依旧, 下班, 中庭, 全国, 鼠年, B, 注册, 还原, 方向\n",
      "Topic 5: 老, 和平, 年, 新, 做, 写字楼, 回忆, 二层, 中国, 广场, 点评, 前, 菓, 局, 建筑, 电影院, 胡同, 开门, 多年, 营业\n",
      "Topic assignments saved in: ../data/review/analysis/topics/topic_assignments.csv\n",
      "Visualization saved as: pyLDAvis/lda_visualization_reviews_merged.html\n"
     ]
    }
   ],
   "source": [
    "file_path = \"../data/review/processed/reviews_merged.txt\"\n",
    "output_file = \"../data/review/analysis/topics/topic_assignments.csv\"\n",
    "\n",
    "lda_topic_modeling_with_assignment(file_path, best_num_topics, output_file)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Datascience",
   "language": "python",
   "name": "datascience"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
