{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "1fc9c849",
   "metadata": {},
   "source": [
    "# Part 2. Topic analysis of positive and negative comments using LDA models"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "7cc87f80",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import gensim\n",
    "from gensim.corpora import Dictionary\n",
    "from gensim.models import LdaModel\n",
    "from gensim.models import CoherenceModel\n",
    "import pyLDAvis.gensim\n",
    "import numpy as np\n",
    "from sklearn.metrics.pairwise import cosine_similarity\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "191f4f6b",
   "metadata": {},
   "source": [
    "## 1. Calculation of the optimal number of topics"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "21860fc4",
   "metadata": {},
   "source": [
    "### Function Design : Use Perplexity and Coherence "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "46643d58",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_optimal_topic_num_by_perplexity(file_path, num_topics_range):\n",
    "    '''\n",
    "    Compute the optimal number of topics.\n",
    "\n",
    "    Parameters:\n",
    "    file_path: str, the file path of the preprocessed text file.\n",
    "    num_topics_range: list, the range of topic numbers to try.\n",
    "\n",
    "    Returns:\n",
    "    best_num_topics: int, the optimal number of topics.\n",
    "    '''\n",
    "\n",
    "    # Read the file and create the corpus.\n",
    "    with open(file_path, 'r', encoding='utf-8') as f:\n",
    "        corpus = [line.strip().split() for line in f]\n",
    "\n",
    "    # Create the dictionary.\n",
    "    dictionary = Dictionary(corpus)\n",
    "\n",
    "    # Train the LDA models with different topic numbers, and calculate the perplexity values.\n",
    "    perplexity_values = []\n",
    "    lda_models = []\n",
    "    for num_topics in num_topics_range:\n",
    "        lda_model = LdaModel(corpus=[dictionary.doc2bow(text) for text in corpus], id2word=dictionary, num_topics=num_topics)\n",
    "        lda_models.append(lda_model)\n",
    "        perplexity_values.append(lda_model.log_perplexity([dictionary.doc2bow(text) for text in corpus]))\n",
    "\n",
    "    # Calculate the coherence scores using the perplexity values.\n",
    "    coherence_scores = [CoherenceModel(model=lda_model, texts=corpus, dictionary=dictionary, coherence='c_v').get_coherence() for lda_model in lda_models]\n",
    "\n",
    "    # Find the optimal number of topics based on the coherence scores.\n",
    "    best_num_topics_index = coherence_scores.index(max(coherence_scores))\n",
    "    best_num_topics = num_topics_range[best_num_topics_index]\n",
    "    \n",
    "    print(\"Optimal number of topics (using perplexity method):\", best_num_topics)\n",
    "\n",
    "    return best_num_topics\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8b2fc02e",
   "metadata": {},
   "source": [
    "### Function Design : Use Cosine_Similarity"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "1520aa3c",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_optimal_topic_num_by_similarity(file_path, num_topics_range):\n",
    "    '''\n",
    "    Compute the optimal number of topics.\n",
    "\n",
    "    Parameters:\n",
    "    file_path: str, the file path of the preprocessed text file.\n",
    "    num_topics_range: list, the range of topic numbers to try.\n",
    "\n",
    "    Returns:\n",
    "    best_num_topics: int, the optimal number of topics.\n",
    "    '''\n",
    "    # Read file and create corpus\n",
    "    with open(file_path, 'r', encoding='utf-8') as f:\n",
    "        corpus = [line.strip().split() for line in f]\n",
    "\n",
    "    # Create dictionary\n",
    "    dictionary = gensim.corpora.Dictionary(corpus)\n",
    "\n",
    "    # Train LDA model and compute cosine similarity between topics for different number of topics\n",
    "    similarity_values = []\n",
    "    for num_topics in num_topics_range:\n",
    "        lda_model = gensim.models.ldamodel.LdaModel(corpus=[dictionary.doc2bow(text) for text in corpus], id2word=dictionary, num_topics=num_topics)\n",
    "        topics_matrix = lda_model.get_topics()\n",
    "        cosine_similarities = cosine_similarity(topics_matrix)\n",
    "        similarity_values.append(np.min(cosine_similarities[np.triu_indices(num_topics, k=1)]))\n",
    "\n",
    "    # Find the optimal number of topics\n",
    "    best_num_topics_index = similarity_values.index(max(similarity_values))\n",
    "    best_num_topics = num_topics_range[best_num_topics_index]\n",
    "    \n",
    "    print(\"Optimal number of topics (using cosine similarity method):\", best_num_topics)\n",
    "    \n",
    "    return best_num_topics\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "974cc298",
   "metadata": {},
   "source": [
    "### Call the function to output the respective optimal number of topics"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "a284f4f7",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create a list of integers for the range of number of topics.\n",
    "num_topics_range = list(range(3, 10))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3d8f9dcc",
   "metadata": {},
   "source": [
    "#### For stores 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "d5bb3037",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Optimal number of topics (using perplexity method): 5\n",
      "Optimal number of topics (using cosine similarity method): 3\n",
      "Ultimate optimal number of topics : 4\n"
     ]
    }
   ],
   "source": [
    "# Set the file path for a text file.\n",
    "file_path = \"../data/review/analysis/polarity/reviews_1_polarity_P.txt\"\n",
    "\n",
    "# Get the optimal number of topics based on perplexity and cosine similarity.\n",
    "best_num_topics_perplexity = get_optimal_topic_num_by_perplexity(file_path, num_topics_range)\n",
    "best_num_topics_similarity = get_optimal_topic_num_by_similarity(file_path, num_topics_range)\n",
    "\n",
    "# Print the ultimate optimal number of topics.\n",
    "P1_best_num_topics = int((best_num_topics_perplexity + best_num_topics_similarity)/2)\n",
    "print(\"Ultimate optimal number of topics :\", P1_best_num_topics)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "b8a73cef",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Optimal number of topics (using perplexity method): 7\n",
      "Optimal number of topics (using cosine similarity method): 3\n",
      "Ultimate optimal number of topics : 5\n"
     ]
    }
   ],
   "source": [
    "# Set the file path for a text file.\n",
    "file_path = \"../data/review/analysis/polarity/reviews_1_polarity_N.txt\"\n",
    "\n",
    "# Get the optimal number of topics based on perplexity and cosine similarity.\n",
    "best_num_topics_perplexity = get_optimal_topic_num_by_perplexity(file_path, num_topics_range)\n",
    "best_num_topics_similarity = get_optimal_topic_num_by_similarity(file_path, num_topics_range)\n",
    "\n",
    "# Print the ultimate optimal number of topics.\n",
    "N1_best_num_topics = int((best_num_topics_perplexity + best_num_topics_similarity)/2)\n",
    "print(\"Ultimate optimal number of topics :\", N1_best_num_topics)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "16a2cbc5",
   "metadata": {},
   "source": [
    "#### For stores 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "2e02acd6",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Optimal number of topics (using perplexity method): 3\n",
      "Optimal number of topics (using cosine similarity method): 3\n",
      "Ultimate optimal number of topics : 3\n"
     ]
    }
   ],
   "source": [
    "# Set the file path for a text file.\n",
    "file_path = \"../data/review/analysis/polarity/reviews_2_polarity_P.txt\"\n",
    "\n",
    "# Get the optimal number of topics based on perplexity and cosine similarity.\n",
    "best_num_topics_perplexity = get_optimal_topic_num_by_perplexity(file_path, num_topics_range)\n",
    "best_num_topics_similarity = get_optimal_topic_num_by_similarity(file_path, num_topics_range)\n",
    "\n",
    "# Print the ultimate optimal number of topics.\n",
    "P2_best_num_topics = int((best_num_topics_perplexity + best_num_topics_similarity)/2)\n",
    "print(\"Ultimate optimal number of topics :\", P2_best_num_topics)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "74457bc5",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Optimal number of topics (using perplexity method): 3\n",
      "Optimal number of topics (using cosine similarity method): 3\n",
      "Ultimate optimal number of topics : 3\n"
     ]
    }
   ],
   "source": [
    "# Set the file path for a text file.\n",
    "file_path = \"../data/review/analysis/polarity/reviews_2_polarity_N.txt\"\n",
    "\n",
    "# Get the optimal number of topics based on perplexity and cosine similarity.\n",
    "best_num_topics_perplexity = get_optimal_topic_num_by_perplexity(file_path, num_topics_range)\n",
    "best_num_topics_similarity = get_optimal_topic_num_by_similarity(file_path, num_topics_range)\n",
    "\n",
    "# Print the ultimate optimal number of topics.\n",
    "N2_best_num_topics = int((best_num_topics_perplexity + best_num_topics_similarity)/2)\n",
    "print(\"Ultimate optimal number of topics :\", N2_best_num_topics)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2609e10c",
   "metadata": {},
   "source": [
    "#### For stores 3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "fa66810a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Optimal number of topics (using perplexity method): 4\n",
      "Optimal number of topics (using cosine similarity method): 3\n",
      "Ultimate optimal number of topics : 3\n"
     ]
    }
   ],
   "source": [
    "# Set the file path for a text file.\n",
    "file_path = \"../data/review/analysis/polarity/reviews_3_polarity_P.txt\"\n",
    "\n",
    "# Get the optimal number of topics based on perplexity and cosine similarity.\n",
    "best_num_topics_perplexity = get_optimal_topic_num_by_perplexity(file_path, num_topics_range)\n",
    "best_num_topics_similarity = get_optimal_topic_num_by_similarity(file_path, num_topics_range)\n",
    "\n",
    "# Print the ultimate optimal number of topics.\n",
    "P3_best_num_topics = int((best_num_topics_perplexity + best_num_topics_similarity)/2)\n",
    "print(\"Ultimate optimal number of topics :\", P3_best_num_topics)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "c24bc816",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Optimal number of topics (using perplexity method): 5\n",
      "Optimal number of topics (using cosine similarity method): 3\n",
      "Ultimate optimal number of topics : 4\n"
     ]
    }
   ],
   "source": [
    "# Set the file path for a text file.\n",
    "file_path = \"../data/review/analysis/polarity/reviews_3_polarity_N.txt\"\n",
    "\n",
    "# Get the optimal number of topics based on perplexity and cosine similarity.\n",
    "best_num_topics_perplexity = get_optimal_topic_num_by_perplexity(file_path, num_topics_range)\n",
    "best_num_topics_similarity = get_optimal_topic_num_by_similarity(file_path, num_topics_range)\n",
    "\n",
    "# Print the ultimate optimal number of topics.\n",
    "N3_best_num_topics = int((best_num_topics_perplexity + best_num_topics_similarity)/2)\n",
    "print(\"Ultimate optimal number of topics :\", N3_best_num_topics)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5259fed7",
   "metadata": {},
   "source": [
    "#### For stores 4"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "656236ab",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Optimal number of topics (using perplexity method): 3\n",
      "Optimal number of topics (using cosine similarity method): 3\n",
      "Ultimate optimal number of topics : 3\n"
     ]
    }
   ],
   "source": [
    "# Set the file path for a text file.\n",
    "file_path = \"../data/review/analysis/polarity/reviews_4_polarity_P.txt\"\n",
    "\n",
    "# Get the optimal number of topics based on perplexity and cosine similarity.\n",
    "best_num_topics_perplexity = get_optimal_topic_num_by_perplexity(file_path, num_topics_range)\n",
    "best_num_topics_similarity = get_optimal_topic_num_by_similarity(file_path, num_topics_range)\n",
    "\n",
    "# Print the ultimate optimal number of topics.\n",
    "P4_best_num_topics = int((best_num_topics_perplexity + best_num_topics_similarity)/2)\n",
    "print(\"Ultimate optimal number of topics :\", P4_best_num_topics)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "e411afc9",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Optimal number of topics (using perplexity method): 7\n",
      "Optimal number of topics (using cosine similarity method): 3\n",
      "Ultimate optimal number of topics : 5\n"
     ]
    }
   ],
   "source": [
    "# Set the file path for a text file.\n",
    "file_path = \"../data/review/analysis/polarity/reviews_4_polarity_N.txt\"\n",
    "\n",
    "# Get the optimal number of topics based on perplexity and cosine similarity.\n",
    "best_num_topics_perplexity = get_optimal_topic_num_by_perplexity(file_path, num_topics_range)\n",
    "best_num_topics_similarity = get_optimal_topic_num_by_similarity(file_path, num_topics_range)\n",
    "\n",
    "# Print the ultimate optimal number of topics.\n",
    "N4_best_num_topics = int((best_num_topics_perplexity + best_num_topics_similarity)/2)\n",
    "print(\"Ultimate optimal number of topics :\", N4_best_num_topics)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d0358879",
   "metadata": {},
   "source": [
    "## 2. Get Topic-Word Distribution"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "44c6c89c",
   "metadata": {},
   "source": [
    "### Function design : LDA model training, topic-word distribution output and visualization"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "bd7c5500",
   "metadata": {},
   "outputs": [],
   "source": [
    "def lda_topic_modeling(file_path, num_topics):\n",
    "    # Read the text file\n",
    "    with open(file_path, \"r\", encoding=\"utf-8\") as f:\n",
    "        texts = [line.strip().split() for line in f]\n",
    "\n",
    "    # Build the dictionary and bag-of-words model\n",
    "    dictionary = Dictionary(texts)\n",
    "    print(dictionary)\n",
    "    \n",
    "    # Filter out extreme terms based on frequency and document proportion\n",
    "    dictionary.filter_extremes(no_below=5, no_above=0.5)\n",
    "    print(dictionary)\n",
    "    \n",
    "    # Convert texts into bag-of-words format\n",
    "    corpus = [dictionary.doc2bow(doc) for doc in texts]\n",
    "\n",
    "    # Train the LDA model\n",
    "    lda_model = LdaModel(corpus=corpus, \n",
    "                         num_topics=num_topics, \n",
    "                         id2word=dictionary, \n",
    "                         random_state=100,\n",
    "                         update_every=1,\n",
    "                         chunksize=100,\n",
    "                         passes=10,\n",
    "                         alpha='auto',\n",
    "                         per_word_topics=True)\n",
    "\n",
    "    # Print the top keywords for each topic\n",
    "    for topic_id in range(num_topics):\n",
    "        topic_words = lda_model.show_topic(topic_id, topn=10)\n",
    "        print(\"Topic {}: {}\".format(topic_id, \", \".join([word for word, prob in topic_words])))\n",
    "\n",
    "    # Compute visualization data for the LDA model\n",
    "    vis_data = pyLDAvis.gensim.prepare(lda_model, corpus, dictionary)\n",
    "\n",
    "    # Extract a portion of the file path as the filename\n",
    "    filename = os.path.splitext(os.path.basename(file_path))[0]\n",
    "    filename = \"pyLDAvis/lda_visualization_{}.html\".format(filename)\n",
    "\n",
    "    # Save the visualization as an HTML file\n",
    "    pyLDAvis.save_html(vis_data, filename)\n",
    "    print(\"Visualization saved as:\", filename)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2089a946",
   "metadata": {},
   "source": [
    "### Call the function to Complete LDA theme analysis"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0e541725",
   "metadata": {},
   "source": [
    "#### For stores 1"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "198bed41",
   "metadata": {},
   "source": [
    "#### Postive review"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "id": "840d0e24",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Dictionary<15034 unique tokens: ['apm', '一圈', '一家', '不错', '云集']...>\n",
      "Dictionary<3103 unique tokens: ['apm', '一圈', '一家', '不错', '云集']...>\n",
      "Topic 0: 打卡, 拍照, 好看, 消毒, 主题, 电影院, 点评, 喜欢, 价格, 超级\n",
      "Topic 1: apm, 活动, 北京, 兰蔻, 可爱, 泡泡玛特, pm, 小样, ️, 扫码\n",
      "Topic 2: 很, 逛, 好, 吃, 多, 王府井, apm, 还, 喜欢, 非常\n",
      "Topic 3: 北京, 品牌, 王府井, apm, 购物, 时尚, 步行街, 王府井大街, 餐饮, 美食\n",
      "Visualization saved as: pyLDAvis/lda_visualization_reviews_1_polarity_P.html\n"
     ]
    }
   ],
   "source": [
    "file_path = \"../data/review/analysis/polarity/reviews_1_polarity_P.txt\"\n",
    "lda_topic_modeling(file_path, P1_best_num_topics)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4eb41550",
   "metadata": {},
   "source": [
    "#### Negative review"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "id": "3ab4074d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Dictionary<5557 unique tokens: ['休息', '地方', '坐下', '座位', '想']...>\n",
      "Dictionary<715 unique tokens: ['休息', '地方', '想', '没有', '顾客']...>\n",
      "Topic 0: 商场, 王府井, 很, apm, 北京, 品牌, 真的, 东安市场, 地下, 非常\n",
      "Topic 1: apm, 活动, 打卡, 北京, 拍照, ️, 展览, 月, 影响, 点评\n",
      "Topic 2: 不, 多, 没, 还, 没有, 买, 说, 逛, 挺, 店\n",
      "Topic 3: 店员, 券, 完全, 钱, 这样, 一件, 厕所, 懒得, 记得, 工作人员\n",
      "Topic 4: 商场, 东西, 吃, 品牌, 王府井, 玩, 不, 很, 不错, 吃饭\n",
      "Visualization saved as: pyLDAvis/lda_visualization_reviews_1_polarity_N.html\n"
     ]
    }
   ],
   "source": [
    "file_path = \"../data/review/analysis/polarity/reviews_1_polarity_N.txt\"\n",
    "lda_topic_modeling(file_path, N1_best_num_topics)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "25f1b21f",
   "metadata": {},
   "source": [
    "#### For stores 2"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b34fd400",
   "metadata": {},
   "source": [
    "#### Postive review"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "id": "1f6033f0",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Dictionary<13572 unique tokens: ['cafelandmark', '一共', '一块', '一杯', '万朵']...>\n",
      "Dictionary<2515 unique tokens: ['一共', '一块', '一杯', '万朵', '上班']...>\n",
      "Topic 0: 怪兽, 可爱, 可可, 工厂, 王府中环, 展览, 吸引, 巧克力, 展, 主题\n",
      "Topic 1: 商场, 很, 王府井, 好, 环境, 品牌, 王府中环, 逛, 非常, 喜欢\n",
      "Topic 2: 很, 还, 买, 不, 孩子, 好, 喜欢, 带, 咖啡, 多\n",
      "Visualization saved as: pyLDAvis/lda_visualization_reviews_2_polarity_P.html\n"
     ]
    }
   ],
   "source": [
    "file_path = \"../data/review/analysis/polarity/reviews_2_polarity_P.txt\"\n",
    "lda_topic_modeling(file_path, P2_best_num_topics)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a1decf05",
   "metadata": {},
   "source": [
    "#### Negative review"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "id": "fb0d017f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Dictionary<3895 unique tokens: ['B', 'DROPOFF', '不是', '东', '位置']...>\n",
      "Dictionary<395 unique tokens: ['B', '不是', '位置', '停车场', '免费']...>\n",
      "Topic 0: 工厂, 活动, 巧克力, 怪兽, 主题, 展览, 很, 怪物, 可可, 创意\n",
      "Topic 1: 孩子, 咖啡, 玩, 冰场, 带, 很, 票, 一些, 特别, 娃\n",
      "Topic 2: 商场, 不, 没有, 王府中环, 很, 王府井, 说, 多, 还, 买\n",
      "Visualization saved as: pyLDAvis/lda_visualization_reviews_2_polarity_N.html\n"
     ]
    }
   ],
   "source": [
    "file_path = \"../data/review/analysis/polarity/reviews_2_polarity_N.txt\"\n",
    "lda_topic_modeling(file_path, N2_best_num_topics)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "77c9ab57",
   "metadata": {},
   "source": [
    "#### For stores 3"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b01f2f33",
   "metadata": {},
   "source": [
    "#### Postive review"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "id": "4ae3525e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Dictionary<8982 unique tokens: ['一楼', '五花八门', '价格', '全国劳模', '北京']...>\n",
      "Dictionary<1468 unique tokens: ['一楼', '价格', '全国劳模', '北京', '品类']...>\n",
      "Topic 0: 化妆品, ️, 专柜, 买, 一层, 优惠, 推荐, 好, 羊毛, 薅\n",
      "Topic 1: 很, 王府井, 商场, 北京, 好, 还, 逛, 感觉, 不错, 不\n",
      "Topic 2: 老, 北京, 和平, 地下, 菓, 局, 回忆, 北京市, 新, 记忆\n",
      "Visualization saved as: pyLDAvis/lda_visualization_reviews_3_polarity_P.html\n"
     ]
    }
   ],
   "source": [
    "file_path = \"../data/review/analysis/polarity/reviews_3_polarity_P.txt\"\n",
    "lda_topic_modeling(file_path, P3_best_num_topics)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5498348c",
   "metadata": {},
   "source": [
    "#### Negative review"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "id": "a7eb53c1",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Dictionary<3461 unique tokens: ['一层', '之选', '优秀', '吃', '商场']...>\n",
      "Dictionary<343 unique tokens: ['一层', '吃', '商场', '地下', '地方']...>\n",
      "Topic 0: 王府井, 商场, 没有, 不, 很, 还, 说, 北京, 没, 真的\n",
      "Topic 1: 老, 北京, 地下, 一层, 二层, 吃, 胡同, 回忆, 怀旧, 王府井\n",
      "Topic 2: 感觉, 买, 小时候, 回忆, 很, 胡同, 东西, 地下, 带, 儿时\n",
      "Topic 3: 菓, 和平, 局, 负, 店, 老, 几十年, 八十年代, 玩具, 餐饮\n",
      "Visualization saved as: pyLDAvis/lda_visualization_reviews_3_polarity_N.html\n"
     ]
    }
   ],
   "source": [
    "file_path = \"../data/review/analysis/polarity/reviews_3_polarity_N.txt\"\n",
    "lda_topic_modeling(file_path, N3_best_num_topics)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e697600c",
   "metadata": {},
   "source": [
    "#### For stores 4"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bdca8b0f",
   "metadata": {},
   "source": [
    "#### Postive review"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "id": "1a445f21",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Dictionary<6685 unique tokens: ['一风堂', '不错', '停车', '吃', '商场']...>\n",
      "Dictionary<996 unique tokens: ['不错', '停车', '吃', '商场', '地下']...>\n",
      "Topic 0: 不, 疫情, 里, 没, 拍照, 没有, 想, 买, 多, 好多\n",
      "Topic 1: 很, 商场, 好, 品牌, 逛, 东方新天地, 喜欢, 多, 非常, 不错\n",
      "Topic 2: 王府井, 东方新天地, 购物, 北京, 东单, 长安街, 餐饮, 商场, 新天地, 东方广场\n",
      "Visualization saved as: pyLDAvis/lda_visualization_reviews_4_polarity_P.html\n"
     ]
    }
   ],
   "source": [
    "file_path = \"../data/review/analysis/polarity/reviews_4_polarity_P.txt\"\n",
    "lda_topic_modeling(file_path, P4_best_num_topics)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9ac57115",
   "metadata": {},
   "source": [
    "#### Negative review"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "id": "ed93eedf",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Dictionary<2630 unique tokens: ['一站式', '不便', '东长安街', '享受', '人流']...>\n",
      "Dictionary<202 unique tokens: ['价格', '停车', '北京', '吃喝玩乐', '白领']...>\n",
      "Topic 0: 东方新天地, 活动, 还, 消费, 非常, 店铺, 王府井, 东单, 不, 店\n",
      "Topic 1: 说, 不, 积分, 没, 还, 疫情, 保安, 问, 没有, 服务台\n",
      "Topic 2: 没有, 不, 地下, 还, 多, 服务, 品牌, 开门, 北京, 东方新天地\n",
      "Topic 3: 王府井, 不是, 没有, 吃, 不, 电影, 写字楼, 没, 还, 长安街\n",
      "Topic 4: 很, 东方新天地, 逛, 地下, 地方, 王府井, 一层, 多, 地铁, 品牌\n",
      "Visualization saved as: pyLDAvis/lda_visualization_reviews_4_polarity_N.html\n"
     ]
    }
   ],
   "source": [
    "file_path = \"../data/review/analysis/polarity/reviews_4_polarity_N.txt\"\n",
    "lda_topic_modeling(file_path, N4_best_num_topics)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Datascience",
   "language": "python",
   "name": "datascience"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
