{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "b88d0ee7",
   "metadata": {},
   "source": [
    "## 文本处理"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "43975152",
   "metadata": {},
   "outputs": [],
   "source": [
    "with open('sentiment_dic/nagtive_dic_2.txt', 'r') as f:  # 替换成实际的文件名\n",
    "    content = f.read().strip()  # 读取文件内容并去掉首尾空格\n",
    "words = content.split('、')  # 将内容按顿号分割成单独的单词，存入列表中\n",
    "\n",
    "with open('sentiment_dic/nagtive_dic_2.txt', 'w') as f:  # 替换成实际的文件名\n",
    "    for word in words:\n",
    "        f.write(word + '\\n')  # 将每个单词写入文件，并换行"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "46e0e72d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 读取第一个txt文件\n",
    "with open('sentiment_dic/nagtive_dic_1.txt', 'r') as f1:\n",
    "    content1 = f1.read().strip()  # 读取文件内容并去掉首尾空格\n",
    "words1 = content1.split('\\n')  # 将内容按换行符分割成单独的单词，存入列表中\n",
    "\n",
    "# 读取第二个txt文件\n",
    "with open('sentiment_dic/nagtive_dic_2.txt', 'r') as f2:\n",
    "    content2 = f2.read().strip()  # 读取文件内容并去掉首尾空格\n",
    "words2 = content2.split('\\n')  # 将内容按换行符分割成单独的单词，存入列表中\n",
    "\n",
    "# 合并两个列表并去除重复的内容\n",
    "words = list(set(words1 + words2))\n",
    "\n",
    "# 将内容写入新的txt文件\n",
    "with open('negative_dic_combined.txt', 'w') as f:\n",
    "    for word in words:\n",
    "        f.write(word + '\\n')  # 将每个单词写入文件，并换行"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "51975373",
   "metadata": {},
   "source": [
    "## 情感值计算demo"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "id": "28512d80",
   "metadata": {},
   "outputs": [],
   "source": [
    "# -*- coding: utf-8 -*-\n",
    "import jieba\n",
    "\n",
    "# 加载情感词典\n",
    "with open('sentiment_dic/senti_dic.txt', 'r', encoding='utf-8') as f:\n",
    "    sentiment_dict = json.load(f)\n",
    "\n",
    "# 加载程度副词词典\n",
    "with open('sentiment_dic/adv_dic.txt', 'r', encoding='utf-8') as f:\n",
    "    degree_dict = json.load(f)\n",
    "\n",
    "# 加载否定词词典\n",
    "with open('sentiment_dic/neg_dic.txt', 'r', encoding='utf-8') as f:\n",
    "    negation_dict = json.load(f)\n",
    "    \n",
    "# 计算单个句子的情感分数\n",
    "def sentiment_score(sen):\n",
    "    seg_list = jieba.cut(sen)  # 分词\n",
    "    seg_list = list(seg_list)\n",
    "    print(seg_list)\n",
    "    emotion_score = 0  # 情感分数\n",
    "    neg_count = 0  # 否定词数量\n",
    "    for i in range(len(seg_list)):\n",
    "        # 检查情感词\n",
    "        if seg_list[i] in sentiment_dict:\n",
    "            score = sentiment_dict[seg_list[i]]\n",
    "            degree_score = 1  # 默认程度系数为1\n",
    "            negation_score = 1  # 默认否定系数为1\n",
    "            # 在有效距离内寻找程度副词和否定词\n",
    "            for j in range(max(0, i-3), i):\n",
    "                if seg_list[j] in degree_dict:\n",
    "                    degree_score *= degree_dict[seg_list[j]]\n",
    "                elif seg_list[j] in negation_dict:\n",
    "                    neg_count += 1\n",
    "            # 根据否定词数量判断情感分数是否反转\n",
    "            if neg_count % 2 == 0:\n",
    "                emotion_score += score * degree_score\n",
    "            else:\n",
    "                emotion_score -= score * degree_score\n",
    "            neg_count = 0  # 重置否定词数量\n",
    "    return emotion_score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "id": "70342833",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['我', '非常', '开心', '，', '甚至', '极其', '开心']\n",
      "4\n"
     ]
    }
   ],
   "source": [
    "# 测试代码\n",
    "sen = '我非常开心，甚至极其开心'\n",
    "score = sentiment_score(sen)\n",
    "print(score)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "id": "94c8294a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['很', '极其', '难过']\n",
      "-3.0\n"
     ]
    }
   ],
   "source": [
    "# 测试代码\n",
    "sen = '很极其难过'\n",
    "score = sentiment_score(sen)\n",
    "print(score)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "id": "98c48408",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['我', '不是', '不', '开心']\n",
      "0\n"
     ]
    }
   ],
   "source": [
    "# 测试代码\n",
    "sen = '我不是不开心'\n",
    "score = sentiment_score(sen)\n",
    "print(score)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "id": "c7307df2",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['我', '虽然', '很', '开心', '的', '，', '但是', '我', '其实', '极其', '不', '开心']\n",
      "-0.5\n"
     ]
    }
   ],
   "source": [
    "# 测试代码\n",
    "sen = '我虽然很开心的，但是我其实极其不开心'\n",
    "score = sentiment_score(sen)\n",
    "print(score)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "id": "0803ac8d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['很久没', '去', '东方', '新天地', '了', '，', '搭', '一号线', '地铁', '到', '王府井', '地铁站', '下车', '从', 'A', '口', '出来', '就', '可以', '直接', '进去', '东方', '新天地', '了', '。', '里面', '的', '商铺', '很多', '，', 'SONY', '旗舰店', '，', '黄金', '首饰店', '，', '服饰', '，', '精品', '手表', '，', '运动', '用品店', '，', '空间', '非常', '大', '，', '建议', '用', '导航', '去', '找', '你', '想', '去', '的', '地方', '，', '不然', '可能', '会', '迷路', '了', '。', ',', '负', '一层', '有', '美食街', '，', '里面', '有', '很多', '好吃', '的', '选择', '，', '火锅', '，', '烤鱼', '，', '简餐', '，', '面包', '坊', '，', '涮涮锅', '，', '煲仔饭', '，', '拉面', '等等', '。', ',', '从', '东方', '新天地', '出去', '就是', '王府井', '步行街', '了', '，', '也', '是', '非常', '方便', '的', '哦', '！']\n",
      "5\n"
     ]
    }
   ],
   "source": [
    "# 测试代码\n",
    "sen = '很久没去东方新天地了，搭一号线地铁到王府井地铁站下车从A口出来就可以直接进去东方新天地了。里面的商铺很多，SONY旗舰店，黄金首饰店，服饰，精品手表，运动用品店，空间非常大，建议用导航去找你想去的地方，不然可能会迷路了。,负一层有美食街，里面有很多好吃的选择，火锅，烤鱼，简餐，面包坊，涮涮锅，煲仔饭，拉面等等。,从东方新天地出去就是王府井步行街了，也是非常方便的哦！'\n",
    "score = sentiment_score(sen)\n",
    "print(score)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Datascience",
   "language": "python",
   "name": "datascience"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
